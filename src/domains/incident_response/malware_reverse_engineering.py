"""
Malware Reverse Engineering Module
Analyzes and deobfuscates malware, generates YARA rules
"""

from typing import List, Dict, Any
from dataclasses import dataclass
from datetime import datetime

from src.utils.llm_client import LLMClient
from src.utils.logger import get_logger

logger = get_logger(__name__)


@dataclass
class MalwareAnalysis:
    """Malware analysis result"""

    sample_id: str
    malware_family: str
    file_type: str
    severity: str
    capabilities: List[str]
    iocs: List[str]
    behavior: str
    deobfuscated_code: str
    yara_rule: str
    mitigation: List[str]


@dataclass
class YARArule:
    """YARA detection rule"""

    rule_name: str
    description: str
    author: str
    date: str
    yara_code: str
    test_result: str


class MalwareReverseEngineeringModule:
    """
    Malware Reverse Engineering Module
    Analyzes malware and generates detection rules
    """

    def __init__(self):
        """Initialize malware reverse engineering module"""
        self.llm_client = LLMClient()
        logger.info("Malware Reverse Engineering Module initialized")

    def analyze_malware(self, code_sample: str, file_type: str = "unknown") -> MalwareAnalysis:
        """Analyze malware sample"""
        logger.info(f"Analyzing {file_type} malware sample")

        system_message = """You are a malware reverse engineer.
Analyze malware for:
- Malware family identification
- Capabilities (C2, persistence, lateral movement)
- Obfuscation techniques
- IOCs
- Behavior analysis"""

        prompt = f"""Analyze this malware sample:

File Type: {file_type}

Sample:
{code_sample[:2000]}

Provide analysis in JSON format:
{{
    "malware_family": "family name or unknown",
    "severity": "CRITICAL" | "HIGH" | "MEDIUM" | "LOW",
    "capabilities": [list of capabilities],
    "iocs": [extracted IOCs],
    "behavior": "detailed behavior description",
    "deobfuscated_code": "deobfuscated/cleaned code snippet",
    "mitigation": [mitigation recommendations]
}}"""

        try:
            result = self.llm_client.complete_with_json(prompt, system_message=system_message)

            sample_id = f"malware_{datetime.now().timestamp()}"

            # Generate YARA rule
            yara_rule = self.generate_yara_rule(
                result.get("malware_family", "unknown"), code_sample
            )

            return MalwareAnalysis(
                sample_id=sample_id,
                malware_family=result.get("malware_family", "unknown"),
                file_type=file_type,
                severity=result.get("severity", "HIGH"),
                capabilities=result.get("capabilities", []),
                iocs=result.get("iocs", []),
                behavior=result.get("behavior", ""),
                deobfuscated_code=result.get("deobfuscated_code", ""),
                yara_rule=yara_rule.yara_code if yara_rule else "",
                mitigation=result.get("mitigation", []),
            )

        except Exception as e:
            logger.error(f"Malware analysis failed: {e}")
            return MalwareAnalysis(
                sample_id="error",
                malware_family="unknown",
                file_type=file_type,
                severity="UNKNOWN",
                capabilities=[],
                iocs=[],
                behavior="",
                deobfuscated_code="",
                yara_rule="",
                mitigation=[f"Analysis error: {e}"],
            )

    def generate_yara_rule(self, malware_name: str, code_sample: str) -> YARArule:
        """Generate YARA detection rule"""
        logger.info(f"Generating YARA rule for {malware_name}")

        system_message = """You are a YARA rule expert.
Create effective YARA rules with:
- Unique string patterns
- Hex patterns
- Metadata
- Appropriate conditions"""

        prompt = f"""Generate a YARA rule for this malware:

Malware: {malware_name}
Sample:
{code_sample[:1500]}

Provide YARA rule in JSON format:
{{
    "rule_name": "rule_name",
    "description": "what this detects",
    "yara_code": "complete YARA rule code",
    "test_result": "expected behavior when tested"
}}"""

        try:
            result = self.llm_client.complete_with_json(prompt, system_message=system_message)

            return YARArule(
                rule_name=result.get("rule_name", f"{malware_name}_detection"),
                description=result.get("description", ""),
                author="LLM Security Platform",
                date=datetime.now().strftime("%Y-%m-%d"),
                yara_code=result.get("yara_code", ""),
                test_result=result.get("test_result", ""),
            )

        except Exception as e:
            logger.error(f"YARA rule generation failed: {e}")
            return YARArule(
                rule_name="error",
                description="",
                author="",
                date="",
                yara_code="",
                test_result=f"Error: {e}",
            )


# Example usage
if __name__ == "__main__":
    reverser = MalwareReverseEngineeringModule()

    malware_sample = """
    import base64, os
    exec(base64.b64decode('aW1wb3J0IHNvY2tldDsgc29ja2V0LmNvbm5lY3Q='))
    """

    analysis = reverser.analyze_malware(malware_sample, "python")
    print(f"Malware Family: {analysis.malware_family}")
    print(f"Severity: {analysis.severity}")
    print(f"Capabilities: {', '.join(analysis.capabilities)}")
