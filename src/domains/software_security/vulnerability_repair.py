"""
Vulnerability Repair Module
Automated vulnerability patching and security fix generation
Based on T5 model approaches and ZeroLeak techniques from the research paper
"""

from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum

from src.utils.llm_client import LLMClient
from src.utils.logger import get_logger
from .vulnerability_detection import Vulnerability, Language

logger = get_logger(__name__)


class RepairStrategy(Enum):
    """Repair strategy types"""
    AUTOMATIC = "automatic"  # Fully automated repair
    ASSISTED = "assisted"    # Human-in-the-loop
    RECOMMENDATION = "recommendation"  # Suggest fixes only


@dataclass
class Patch:
    """Code patch for vulnerability"""
    patch_id: str
    vulnerability_id: str
    original_code: str
    patched_code: str
    diff: str
    explanation: str
    confidence: float
    tested: bool
    side_effects: List[str]


@dataclass
class RepairReport:
    """Vulnerability repair report"""
    repair_id: str
    total_vulnerabilities: int
    repaired_count: int
    failed_count: int
    patches: List[Patch]
    summary: str
    recommendations: List[str]


class VulnerabilityRepairModule:
    """
    Vulnerability Repair Module using LLM
    Generates secure patches for detected vulnerabilities
    """

    def __init__(self):
        """Initialize vulnerability repair module"""
        self.llm_client = LLMClient()
        logger.info("Vulnerability Repair Module initialized")

    def generate_patch(
        self,
        vulnerability: Vulnerability,
        code: str,
        language: Language,
        strategy: RepairStrategy = RepairStrategy.AUTOMATIC
    ) -> Patch:
        """
        Generate patch for a specific vulnerability

        Args:
            vulnerability: Detected vulnerability
            code: Full source code context
            language: Programming language
            strategy: Repair strategy to use

        Returns:
            Patch: Generated patch with fixes
        """
        logger.info(
            f"Generating patch for {vulnerability.name} ({vulnerability.cwe_id})"
        )

        system_message = f"""You are an expert security engineer specializing in {language.value}.
Generate secure patches that fix vulnerabilities while maintaining code functionality.
Ensure fixes follow secure coding best practices and don't introduce new issues."""

        prompt = f"""Generate a secure patch for this vulnerability:

**Vulnerability Details:**
- Name: {vulnerability.name}
- CWE: {vulnerability.cwe_id}
- Severity: {vulnerability.severity.value}
- Description: {vulnerability.description}
- Location: Line {vulnerability.location['line_start']}-{vulnerability.location['line_end']}

**Vulnerable Code:**
```{language.value}
{vulnerability.code_snippet}
```

**Full Context:**
```{language.value}
{code}
```

**Current Recommendation:**
{vulnerability.recommendation}

Generate a secure patch that:
1. Completely fixes the vulnerability
2. Maintains the original functionality
3. Follows {language.value} best practices
4. Doesn't introduce new vulnerabilities
5. Is production-ready

Provide response in JSON format:
{{
    "original_code": "the vulnerable code section",
    "patched_code": "the secure fixed code",
    "diff": "unified diff format showing changes",
    "explanation": "detailed explanation of the fix",
    "confidence": float (0.0-1.0),
    "potential_side_effects": ["list any potential side effects"],
    "testing_recommendations": ["how to test this fix"]
}}"""

        try:
            result = self.llm_client.complete_with_json(
                prompt,
                system_message=system_message,
                max_tokens=2000
            )

            patch = Patch(
                patch_id=f"PATCH-{hash(vulnerability.vuln_id) % 10000:04d}",
                vulnerability_id=vulnerability.vuln_id,
                original_code=result.get("original_code", vulnerability.code_snippet),
                patched_code=result.get("patched_code", ""),
                diff=result.get("diff", ""),
                explanation=result.get("explanation", ""),
                confidence=result.get("confidence", 0.8),
                tested=False,
                side_effects=result.get("potential_side_effects", [])
            )

            logger.info(f"Patch generated: {patch.patch_id} (confidence: {patch.confidence:.2f})")
            return patch

        except Exception as e:
            logger.error(f"Patch generation failed: {e}")
            raise

    def repair_multiple_vulnerabilities(
        self,
        vulnerabilities: List[Vulnerability],
        code: str,
        language: Language
    ) -> RepairReport:
        """
        Repair multiple vulnerabilities in code

        Args:
            vulnerabilities: List of vulnerabilities to fix
            code: Source code
            language: Programming language

        Returns:
            RepairReport: Complete repair report
        """
        logger.info(f"Repairing {len(vulnerabilities)} vulnerabilities")

        patches = []
        repaired_count = 0
        failed_count = 0

        for vuln in vulnerabilities:
            try:
                patch = self.generate_patch(vuln, code, language)
                patches.append(patch)
                repaired_count += 1
            except Exception as e:
                logger.error(f"Failed to repair {vuln.vuln_id}: {e}")
                failed_count += 1

        # Generate summary
        summary = self._generate_repair_summary(patches, repaired_count, failed_count)

        report = RepairReport(
            repair_id=f"REPAIR-{hash(code) % 10000:04d}",
            total_vulnerabilities=len(vulnerabilities),
            repaired_count=repaired_count,
            failed_count=failed_count,
            patches=patches,
            summary=summary,
            recommendations=self._generate_recommendations(patches)
        )

        logger.info(
            f"Repair complete: {repaired_count} repaired, {failed_count} failed"
        )
        return report

    def apply_security_patterns(
        self,
        code: str,
        language: Language,
        patterns: List[str]
    ) -> str:
        """
        Apply security patterns to code

        Args:
            code: Source code
            language: Programming language
            patterns: Security patterns to apply

        Returns:
            str: Refactored code with security patterns
        """
        logger.info(f"Applying {len(patterns)} security patterns")

        system_message = f"""You are a security architect refactoring {language.value} code.
Apply security patterns and best practices while maintaining functionality."""

        patterns_str = "\n".join(f"- {p}" for p in patterns)

        prompt = f"""Refactor this code to apply these security patterns:

**Security Patterns to Apply:**
{patterns_str}

**Original Code:**
```{language.value}
{code}
```

Generate secure, refactored code that:
1. Implements all specified security patterns
2. Maintains original functionality
3. Follows SOLID principles
4. Is well-documented
5. Includes error handling

Provide:
{{
    "refactored_code": "complete refactored code",
    "changes_summary": "summary of applied patterns",
    "improvements": ["list of security improvements made"]
}}"""

        try:
            result = self.llm_client.complete_with_json(
                prompt,
                system_message=system_message,
                max_tokens=2500
            )

            refactored = result.get("refactored_code", code)
            logger.info(f"Security patterns applied successfully")
            return refactored

        except Exception as e:
            logger.error(f"Pattern application failed: {e}")
            return code

    def validate_fix(
        self,
        original_code: str,
        patched_code: str,
        language: Language,
        vulnerability: Vulnerability
    ) -> Dict[str, Any]:
        """
        Validate that a patch correctly fixes the vulnerability

        Args:
            original_code: Original vulnerable code
            patched_code: Patched code
            language: Programming language
            vulnerability: The vulnerability being fixed

        Returns:
            Dict: Validation results
        """
        logger.info(f"Validating patch for {vulnerability.vuln_id}")

        system_message = """You are a security verification expert.
Thoroughly validate that patches correctly fix vulnerabilities without introducing new issues."""

        prompt = f"""Validate this security patch:

**Vulnerability:** {vulnerability.name} ({vulnerability.cwe_id})
**Description:** {vulnerability.description}

**Original Code:**
```{language.value}
{original_code}
```

**Patched Code:**
```{language.value}
{patched_code}
```

Verify:
1. The vulnerability is completely fixed
2. No new vulnerabilities are introduced
3. Functionality is preserved
4. Code quality is maintained or improved
5. No performance regressions

Provide validation result in JSON:
{{
    "vulnerability_fixed": boolean,
    "new_vulnerabilities": ["list any new vulnerabilities introduced"],
    "functionality_preserved": boolean,
    "code_quality_score": float (0-10),
    "issues_found": ["list any issues"],
    "recommendations": ["additional recommendations"],
    "overall_verdict": "APPROVED|NEEDS_REVISION|REJECTED"
}}"""

        try:
            result = self.llm_client.complete_with_json(
                prompt,
                system_message=system_message
            )

            logger.info(f"Validation verdict: {result.get('overall_verdict', 'UNKNOWN')}")
            return result

        except Exception as e:
            logger.error(f"Validation failed: {e}")
            return {"error": str(e), "overall_verdict": "ERROR"}

    def generate_test_cases(
        self,
        patch: Patch,
        language: Language
    ) -> List[str]:
        """
        Generate test cases to verify the patch

        Args:
            patch: The patch to test
            language: Programming language

        Returns:
            List[str]: Generated test cases
        """
        logger.info(f"Generating test cases for {patch.patch_id}")

        system_message = f"""You are a test engineer writing security tests for {language.value}.
Generate comprehensive test cases that verify patches work correctly."""

        prompt = f"""Generate test cases for this security patch:

**Original Code:**
```{language.value}
{patch.original_code}
```

**Patched Code:**
```{language.value}
{patch.patched_code}
```

**Fix Explanation:**
{patch.explanation}

Generate test cases that:
1. Verify the vulnerability is fixed
2. Test edge cases
3. Ensure functionality is preserved
4. Test for regressions
5. Include both positive and negative tests

Provide in JSON format:
{{
    "test_cases": [
        {{
            "name": "test name",
            "code": "test code",
            "description": "what this tests",
            "expected_result": "expected outcome"
        }}
    ]
}}"""

        try:
            result = self.llm_client.complete_with_json(
                prompt,
                system_message=system_message,
                max_tokens=2000
            )

            test_cases = [
                tc["code"]
                for tc in result.get("test_cases", [])
            ]

            logger.info(f"Generated {len(test_cases)} test cases")
            return test_cases

        except Exception as e:
            logger.error(f"Test generation failed: {e}")
            return []

    def _generate_repair_summary(
        self,
        patches: List[Patch],
        repaired: int,
        failed: int
    ) -> str:
        """Generate summary of repair operations"""
        total = repaired + failed
        success_rate = (repaired / total * 100) if total > 0 else 0

        avg_confidence = (
            sum(p.confidence for p in patches) / len(patches)
            if patches else 0
        )

        return f"""Repair Summary:
- Total vulnerabilities: {total}
- Successfully repaired: {repaired}
- Failed repairs: {failed}
- Success rate: {success_rate:.1f}%
- Average patch confidence: {avg_confidence:.2f}

All patches should be reviewed and tested before deployment."""

    def _generate_recommendations(self, patches: List[Patch]) -> List[str]:
        """Generate recommendations based on patches"""
        recommendations = [
            "Review all generated patches before applying to production",
            "Run comprehensive test suite after applying patches",
            "Perform security regression testing",
        ]

        # Add specific recommendations based on patches
        if any(p.confidence < 0.8 for p in patches):
            recommendations.append(
                "Some patches have low confidence - manual review strongly recommended"
            )

        if any(p.side_effects for p in patches):
            recommendations.append(
                "Some patches may have side effects - thorough testing required"
            )

        return recommendations


# Example usage
if __name__ == "__main__":
    from .vulnerability_detection import VulnerabilityDetectionModule, Severity

    repairer = VulnerabilityRepairModule()

    # Test: Repair SQL Injection vulnerability
    print("=" * 70)
    print("VULNERABILITY REPAIR DEMONSTRATION")
    print("=" * 70)

    # Create a sample vulnerability
    sql_injection_vuln = Vulnerability(
        vuln_id="VULN-001",
        name="SQL Injection",
        description="User input directly concatenated into SQL query",
        severity=Severity.CRITICAL,
        cwe_id="CWE-89",
        location={"file": "user.py", "line_start": 3, "line_end": 3, "function": "get_user"},
        code_snippet='query = f"SELECT * FROM users WHERE id = {user_id}"',
        recommendation="Use parameterized queries",
        references=[],
        confidence=0.95
    )

    vulnerable_code = """
def get_user(user_id):
    query = f"SELECT * FROM users WHERE id = {user_id}"
    return db.execute(query)
"""

    try:
        # Generate patch
        print("\n1. Generating security patch...")
        patch = repairer.generate_patch(
            sql_injection_vuln,
            vulnerable_code,
            Language.PYTHON
        )

        print(f"\nPatch ID: {patch.patch_id}")
        print(f"Confidence: {patch.confidence:.0%}")
        print(f"\nðŸ“ Explanation:\n{patch.explanation}")
        print(f"\nðŸ”§ Patched Code:\n{patch.patched_code}")

        # Validate the fix
        print("\n" + "=" * 70)
        print("2. Validating the patch...")
        validation = repairer.validate_fix(
            vulnerable_code,
            patch.patched_code,
            Language.PYTHON,
            sql_injection_vuln
        )

        print(f"\nValidation Result: {validation.get('overall_verdict', 'UNKNOWN')}")
        print(f"Vulnerability Fixed: {validation.get('vulnerability_fixed', False)}")
        print(f"Functionality Preserved: {validation.get('functionality_preserved', False)}")
        print(f"Code Quality Score: {validation.get('code_quality_score', 0)}/10")

        # Generate test cases
        print("\n" + "=" * 70)
        print("3. Generating test cases...")
        test_cases = repairer.generate_test_cases(patch, Language.PYTHON)

        print(f"\nGenerated {len(test_cases)} test cases")
        if test_cases:
            print(f"\nSample Test Case:\n{test_cases[0][:200]}...")

    except Exception as e:
        print(f"\nâŒ Error: {e}")

    # Test: Apply security patterns
    print("\n" + "=" * 70)
    print("4. Applying Security Patterns")
    print("=" * 70)

    insecure_code = """
def process_payment(amount, card_number):
    # Store credit card in plain text
    db.save('cards', card_number)
    return make_payment(amount, card_number)
"""

    try:
        refactored = repairer.apply_security_patterns(
            insecure_code,
            Language.PYTHON,
            [
                "PCI DSS compliance for payment data",
                "Encryption at rest",
                "Input validation",
                "Audit logging"
            ]
        )

        print(f"\nðŸ”’ Refactored Code:\n{refactored[:300]}...")

    except Exception as e:
        print(f"\nâŒ Error: {e}")
