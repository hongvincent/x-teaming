"""
Vulnerability Detection Module
Static code analysis for security vulnerabilities across multiple languages
Based on LATTE and GPT-based approaches from the research paper
"""

from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from enum import Enum

from src.utils.llm_client import LLMClient
from src.utils.logger import get_logger

logger = get_logger(__name__)


class Language(Enum):
    """Supported programming languages"""
    PYTHON = "python"
    JAVASCRIPT = "javascript"
    JAVA = "java"
    C = "c"
    CPP = "cpp"
    GO = "go"
    RUST = "rust"
    SOLIDITY = "solidity"
    PHP = "php"
    RUBY = "ruby"


class Severity(Enum):
    """Vulnerability severity levels"""
    CRITICAL = "CRITICAL"
    HIGH = "HIGH"
    MEDIUM = "MEDIUM"
    LOW = "LOW"
    INFO = "INFO"


@dataclass
class Vulnerability:
    """Detected vulnerability"""
    vuln_id: str
    name: str
    description: str
    severity: Severity
    cwe_id: str  # Common Weakness Enumeration
    location: Dict[str, Any]  # file, line, function
    code_snippet: str
    recommendation: str
    references: List[str]
    confidence: float  # 0.0 to 1.0


@dataclass
class VulnerabilityReport:
    """Complete vulnerability scan report"""
    scan_id: str
    language: Language
    total_vulnerabilities: int
    critical_count: int
    high_count: int
    medium_count: int
    low_count: int
    vulnerabilities: List[Vulnerability]
    scan_summary: str
    remediation_priority: List[str]


class VulnerabilityDetectionModule:
    """
    Vulnerability Detection Module using LLM for static code analysis
    Supports multiple programming languages and CWE classification
    """

    def __init__(self):
        """Initialize vulnerability detection module"""
        self.llm_client = LLMClient()
        logger.info("Vulnerability Detection Module initialized")

    def scan_code(
        self,
        code: str,
        language: Language,
        filename: Optional[str] = None
    ) -> VulnerabilityReport:
        """
        Scan code for vulnerabilities

        Args:
            code: Source code to analyze
            language: Programming language
            filename: Optional filename for context

        Returns:
            VulnerabilityReport: Comprehensive vulnerability report
        """
        logger.info(f"Scanning {language.value} code for vulnerabilities")

        system_message = f"""You are an expert security code reviewer specializing in {language.value}.
Perform comprehensive static analysis to identify security vulnerabilities.
Focus on OWASP Top 10, CWE classifications, and language-specific security issues.
Be thorough and precise in your analysis."""

        prompt = f"""Analyze this {language.value} code for security vulnerabilities:

{'File: ' + filename if filename else ''}

```{language.value}
{code}
```

Perform a comprehensive security analysis and identify ALL vulnerabilities including:
1. Injection flaws (SQL, Command, LDAP, etc.)
2. Authentication/Authorization issues
3. Sensitive data exposure
4. XML/XXE vulnerabilities
5. Broken access control
6. Security misconfiguration
7. XSS (Cross-Site Scripting)
8. Insecure deserialization
9. Using components with known vulnerabilities
10. Insufficient logging and monitoring
11. Memory safety issues (for C/C++)
12. Race conditions
13. Integer overflow/underflow
14. Path traversal
15. CSRF vulnerabilities

For EACH vulnerability found, provide in JSON format:
{{
    "vulnerabilities": [
        {{
            "name": "vulnerability name",
            "description": "detailed description of the issue",
            "severity": "CRITICAL|HIGH|MEDIUM|LOW|INFO",
            "cwe_id": "CWE-XXX",
            "line_start": line number where vulnerability starts,
            "line_end": line number where vulnerability ends,
            "function_name": "affected function/method name",
            "code_snippet": "the vulnerable code line(s)",
            "recommendation": "specific fix recommendation",
            "confidence": float between 0.0 and 1.0
        }}
    ],
    "summary": "overall security assessment",
    "risk_level": "CRITICAL|HIGH|MEDIUM|LOW"
}}"""

        try:
            result = self.llm_client.complete_with_json(
                prompt,
                system_message=system_message,
                max_tokens=3000
            )

            # Parse vulnerabilities
            vulnerabilities = []
            vuln_data_list = result.get("vulnerabilities", [])

            for i, vuln_data in enumerate(vuln_data_list):
                vuln = Vulnerability(
                    vuln_id=f"VULN-{i+1:03d}",
                    name=vuln_data.get("name", "Unknown Vulnerability"),
                    description=vuln_data.get("description", ""),
                    severity=Severity[vuln_data.get("severity", "MEDIUM")],
                    cwe_id=vuln_data.get("cwe_id", "CWE-000"),
                    location={
                        "file": filename or "unknown",
                        "line_start": vuln_data.get("line_start", 0),
                        "line_end": vuln_data.get("line_end", 0),
                        "function": vuln_data.get("function_name", "unknown")
                    },
                    code_snippet=vuln_data.get("code_snippet", ""),
                    recommendation=vuln_data.get("recommendation", ""),
                    references=[],
                    confidence=vuln_data.get("confidence", 0.8)
                )
                vulnerabilities.append(vuln)

            # Count by severity
            severity_counts = {
                Severity.CRITICAL: sum(1 for v in vulnerabilities if v.severity == Severity.CRITICAL),
                Severity.HIGH: sum(1 for v in vulnerabilities if v.severity == Severity.HIGH),
                Severity.MEDIUM: sum(1 for v in vulnerabilities if v.severity == Severity.MEDIUM),
                Severity.LOW: sum(1 for v in vulnerabilities if v.severity == Severity.LOW),
            }

            # Generate remediation priority
            priority = self._generate_remediation_priority(vulnerabilities)

            report = VulnerabilityReport(
                scan_id=f"SCAN-{hash(code) % 10000:04d}",
                language=language,
                total_vulnerabilities=len(vulnerabilities),
                critical_count=severity_counts[Severity.CRITICAL],
                high_count=severity_counts[Severity.HIGH],
                medium_count=severity_counts[Severity.MEDIUM],
                low_count=severity_counts[Severity.LOW],
                vulnerabilities=vulnerabilities,
                scan_summary=result.get("summary", ""),
                remediation_priority=priority
            )

            logger.info(f"Scan complete: {len(vulnerabilities)} vulnerabilities found")
            return report

        except Exception as e:
            logger.error(f"Vulnerability scan failed: {e}")
            raise

    def detect_cwe(self, code: str, language: Language) -> List[str]:
        """
        Detect specific CWE (Common Weakness Enumeration) patterns

        Args:
            code: Source code
            language: Programming language

        Returns:
            List[str]: List of detected CWE IDs
        """
        logger.info(f"Detecting CWE patterns in {language.value} code")

        system_message = """You are a security expert specializing in CWE classification.
Identify Common Weakness Enumeration patterns in code.
Reference the official CWE database for accurate classification."""

        prompt = f"""Analyze this {language.value} code and identify all CWE (Common Weakness Enumeration) patterns:

```{language.value}
{code}
```

For each CWE found, provide:
1. CWE ID (e.g., CWE-89 for SQL Injection)
2. Brief description
3. Line numbers where it occurs

Respond in JSON format:
{{
    "cwe_findings": [
        {{
            "cwe_id": "CWE-XXX",
            "name": "CWE name",
            "description": "brief description",
            "lines": [line numbers]
        }}
    ]
}}"""

        try:
            result = self.llm_client.complete_with_json(
                prompt,
                system_message=system_message
            )

            cwe_ids = [
                finding["cwe_id"]
                for finding in result.get("cwe_findings", [])
            ]

            logger.info(f"Detected {len(cwe_ids)} CWE patterns")
            return cwe_ids

        except Exception as e:
            logger.error(f"CWE detection failed: {e}")
            return []

    def analyze_dependencies(
        self,
        requirements: str,
        package_manager: str = "pip"
    ) -> Dict[str, Any]:
        """
        Analyze dependencies for known vulnerabilities

        Args:
            requirements: Requirements/package file content
            package_manager: Package manager (pip, npm, maven, etc.)

        Returns:
            Dict: Dependency vulnerability analysis
        """
        logger.info(f"Analyzing dependencies ({package_manager})")

        system_message = """You are a dependency security analyst.
Identify packages with known vulnerabilities, outdated versions, and security advisories.
Reference CVE databases and security bulletins."""

        prompt = f"""Analyze these {package_manager} dependencies for security vulnerabilities:

```
{requirements}
```

Check for:
1. Packages with known CVEs
2. Outdated versions with security patches
3. Deprecated packages
4. License compliance issues
5. Transitive dependency risks

Respond in JSON format:
{{
    "vulnerable_packages": [
        {{
            "package": "package name",
            "version": "current version",
            "vulnerabilities": ["CVE-XXXX-XXXXX"],
            "severity": "CRITICAL|HIGH|MEDIUM|LOW",
            "fixed_version": "version with fix",
            "recommendation": "update recommendation"
        }}
    ],
    "total_packages": number,
    "vulnerable_count": number,
    "risk_score": float (0-10)
}}"""

        try:
            result = self.llm_client.complete_with_json(
                prompt,
                system_message=system_message
            )

            logger.info(
                f"Dependency analysis complete: "
                f"{result.get('vulnerable_count', 0)} vulnerable packages"
            )
            return result

        except Exception as e:
            logger.error(f"Dependency analysis failed: {e}")
            return {
                "vulnerable_packages": [],
                "total_packages": 0,
                "vulnerable_count": 0,
                "error": str(e)
            }

    def compare_with_secure_patterns(
        self,
        code: str,
        language: Language
    ) -> Dict[str, Any]:
        """
        Compare code against secure coding patterns

        Args:
            code: Source code to analyze
            language: Programming language

        Returns:
            Dict: Pattern compliance analysis
        """
        logger.info(f"Comparing with secure coding patterns ({language.value})")

        system_message = f"""You are a secure coding expert for {language.value}.
Compare code against industry-standard secure coding practices and patterns.
Reference OWASP Secure Coding Practices, CERT Coding Standards, etc."""

        prompt = f"""Analyze this {language.value} code against secure coding patterns:

```{language.value}
{code}
```

Evaluate compliance with:
1. Input validation patterns
2. Output encoding practices
3. Authentication/authorization patterns
4. Cryptography usage
5. Error handling and logging
6. Secure configuration
7. Memory management (if applicable)

Provide:
{{
    "compliant_patterns": ["list of followed secure patterns"],
    "violations": [
        {{
            "pattern": "violated pattern name",
            "severity": "HIGH|MEDIUM|LOW",
            "location": "where in code",
            "recommendation": "how to fix"
        }}
    ],
    "compliance_score": float (0-100),
    "overall_assessment": "summary"
}}"""

        try:
            result = self.llm_client.complete_with_json(
                prompt,
                system_message=system_message
            )

            logger.info(
                f"Pattern analysis complete: "
                f"Compliance score: {result.get('compliance_score', 0):.1f}%"
            )
            return result

        except Exception as e:
            logger.error(f"Pattern comparison failed: {e}")
            return {"error": str(e)}

    def _generate_remediation_priority(
        self,
        vulnerabilities: List[Vulnerability]
    ) -> List[str]:
        """
        Generate prioritized remediation recommendations

        Args:
            vulnerabilities: List of detected vulnerabilities

        Returns:
            List[str]: Prioritized remediation steps
        """
        # Sort by severity and confidence
        severity_order = {
            Severity.CRITICAL: 4,
            Severity.HIGH: 3,
            Severity.MEDIUM: 2,
            Severity.LOW: 1,
            Severity.INFO: 0
        }

        sorted_vulns = sorted(
            vulnerabilities,
            key=lambda v: (severity_order[v.severity], v.confidence),
            reverse=True
        )

        priorities = []
        for i, vuln in enumerate(sorted_vulns[:10], 1):  # Top 10
            priority = (
                f"{i}. [{vuln.severity.value}] {vuln.name} "
                f"({vuln.cwe_id}) - {vuln.recommendation}"
            )
            priorities.append(priority)

        return priorities

    def generate_security_report(
        self,
        report: VulnerabilityReport,
        format: str = "markdown"
    ) -> str:
        """
        Generate formatted security report

        Args:
            report: Vulnerability report
            format: Output format (markdown, html, json)

        Returns:
            str: Formatted report
        """
        if format == "markdown":
            return self._generate_markdown_report(report)
        elif format == "json":
            import json
            return json.dumps({
                "scan_id": report.scan_id,
                "language": report.language.value,
                "total_vulnerabilities": report.total_vulnerabilities,
                "vulnerabilities": [
                    {
                        "id": v.vuln_id,
                        "name": v.name,
                        "severity": v.severity.value,
                        "cwe": v.cwe_id
                    }
                    for v in report.vulnerabilities
                ]
            }, indent=2)
        else:
            return str(report)

    def _generate_markdown_report(self, report: VulnerabilityReport) -> str:
        """Generate markdown formatted report"""
        lines = [
            f"# Security Vulnerability Report",
            f"",
            f"**Scan ID**: {report.scan_id}",
            f"**Language**: {report.language.value}",
            f"**Total Vulnerabilities**: {report.total_vulnerabilities}",
            f"",
            f"## Summary",
            f"",
            f"- ðŸ”´ Critical: {report.critical_count}",
            f"- ðŸŸ  High: {report.high_count}",
            f"- ðŸŸ¡ Medium: {report.medium_count}",
            f"- ðŸŸ¢ Low: {report.low_count}",
            f"",
            f"{report.scan_summary}",
            f"",
            f"## Vulnerabilities",
            f""
        ]

        for vuln in report.vulnerabilities:
            lines.extend([
                f"### {vuln.vuln_id}: {vuln.name}",
                f"",
                f"- **Severity**: {vuln.severity.value}",
                f"- **CWE**: {vuln.cwe_id}",
                f"- **Location**: {vuln.location['file']}:{vuln.location['line_start']}",
                f"- **Confidence**: {vuln.confidence:.0%}",
                f"",
                f"**Description**: {vuln.description}",
                f"",
                f"**Code**:",
                f"```",
                vuln.code_snippet,
                f"```",
                f"",
                f"**Recommendation**: {vuln.recommendation}",
                f"",
                f"---",
                f""
            ])

        return "\n".join(lines)


# Example usage
if __name__ == "__main__":
    detector = VulnerabilityDetectionModule()

    # Test 1: SQL Injection vulnerability
    print("=" * 70)
    print("TEST 1: SQL Injection Detection")
    print("=" * 70)

    vulnerable_python = """
def get_user(user_id):
    # Vulnerable to SQL injection
    query = f"SELECT * FROM users WHERE id = {user_id}"
    return db.execute(query)

def login(username, password):
    # Also vulnerable
    sql = "SELECT * FROM users WHERE username='" + username + "' AND password='" + password + "'"
    result = database.query(sql)
    return result
"""

    try:
        report = detector.scan_code(
            vulnerable_python,
            Language.PYTHON,
            filename="user_auth.py"
        )

        print(f"\nScan ID: {report.scan_id}")
        print(f"Total Vulnerabilities: {report.total_vulnerabilities}")
        print(f"Critical: {report.critical_count}, High: {report.high_count}")
        print(f"\nVulnerabilities Found:")

        for vuln in report.vulnerabilities[:3]:
            print(f"\n  {vuln.vuln_id}: {vuln.name}")
            print(f"  Severity: {vuln.severity.value}")
            print(f"  CWE: {vuln.cwe_id}")
            print(f"  Line: {vuln.location['line_start']}")
            print(f"  Recommendation: {vuln.recommendation[:100]}...")

    except Exception as e:
        print(f"Error: {e}")

    # Test 2: CWE Detection
    print("\n" + "=" * 70)
    print("TEST 2: CWE Pattern Detection")
    print("=" * 70)

    try:
        cwe_list = detector.detect_cwe(vulnerable_python, Language.PYTHON)
        print(f"\nDetected CWE Patterns: {', '.join(cwe_list)}")
    except Exception as e:
        print(f"Error: {e}")

    # Test 3: Dependency Analysis
    print("\n" + "=" * 70)
    print("TEST 3: Dependency Vulnerability Analysis")
    print("=" * 70)

    requirements = """
flask==0.12.0
django==1.11.0
requests==2.6.0
pillow==6.0.0
"""

    try:
        dep_report = detector.analyze_dependencies(requirements, "pip")
        print(f"\nTotal Packages: {dep_report.get('total_packages', 0)}")
        print(f"Vulnerable Packages: {dep_report.get('vulnerable_count', 0)}")
        print(f"Risk Score: {dep_report.get('risk_score', 0):.1f}/10")

        for pkg in dep_report.get('vulnerable_packages', [])[:3]:
            print(f"\n  Package: {pkg['package']} v{pkg['version']}")
            print(f"  Severity: {pkg['severity']}")
            print(f"  Fix: Upgrade to {pkg['fixed_version']}")
    except Exception as e:
        print(f"Error: {e}")
